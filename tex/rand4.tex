\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[left=1.25in,top=1.25in,right=1.25in,bottom=1.25in,head=1.25in]{geometry}
\usepackage{amsmath,amssymb,amsthm}

\usepackage{import}
\usepackage{xifthen}
\usepackage{pdfpages}
\usepackage{transparent}

\newcommand{\incfig}[1]{%
    \def\svgwidth{\columnwidth}
    \import{./figures/}{#1.pdf_tex}
}



\newtheorem{exo}{Exercise}
\def\P{\mathbb{P}}
\def\E{\mathbb{E}}

\title{Randomised Algorithms \\
Winter term 2022/2023, Exercise Sheet No. 4}

\author{
    \textbf{Authors:} \\
    Ben Ayad, Mohamed Ayoub \\
    Kamzon, Noureddine
}

\begin{document}

\maketitle


\begin{exo}{\ \\}

\noindent
\textbf{(a)} Every deterministic algorithm has a predefined list of $S$ that it checks in the same order, hence is $s^*$ was the last item in the algorithm's list, it would be forced to try all words in $S$. To know this input we can try a naive approach, try all words of $S$ as input, and collect the time it took the algorithm to break the lock, the input we are looking for would take the longest time.  \\

\noindent
\textbf{(b)} For $|S|=1$ there is only one input and hence, $\P[T=1] = 1 = 1/|S|$. Let's suppose that for some set $S^{'}$ of size $n \geq 1$ we have $\P[T=k] = \frac{1}{|S^{'}|}$ for all $1 \leq k \leq n$. 

Let $S$ be a set of size $n+1$, we have the following for some $k \in \{1, \dots ,n+1\}\colon$

\begin{align*}
    \P[T = k] &= \P[T=k |T \leq n ]\P[T \leq n] +  \P[T=k |T = n+1 ]\P[T = n+1]
\end{align*}
 
For $k \leq n$: \\
$\P[T=k | T \leq n] = \frac{1}{n}$ (using the hypothesis, knowing that $T \leq n$, gives us one less choice and puts us back to the hypothesis $n$), and $\P[T=k |T = n+1 ] = 0$, which yields, $\P[T = k] = \frac{1}{n} \P[T \leq n] = \frac{1}{n} \frac{n}{n+1} = \frac{1}{n+1}   $

For $k = n+1$: \\
$\P[T=k] = \P[T=k|T=n+1] \P[T=n+1] = 1 \frac{1}{n+1} = \frac{1}{n+1} $
\end{exo}

Hence, for all $k \in \{1, \dots, n+1\}\colon \P[T=k] = \frac{1}{n+1}$ which completes our induction. \\

\noindent
For $|S| = n$, let's compute $\E[T]$:
\begin{align*}
    \E[T] &= \sum_{k=1}^{n} k \P[T=k] \\
          &= \frac{1}{n} \frac{n(n+1)}{2} \\
          &= \frac{n+1}{2} 
\end{align*}


\noindent

\textbf{(c)} The hardest distribution $p$ is a uniform one, otherwise (if $p$ favoured some combinations), then there are always some deterministic algorithms that would check for those combinations first, and hence make the expected numbers of checks smaller in average. \\

Let $p$ be the uniform distribution over words of $S$, let $A$ be any optimal determinitic algorithm, hence, for each $k \in \{1, \dots, |S|\}$, there is one and only one input $I_j$ such that $k = C(I_j, A)$, this observation justifies the equality \textbf{[*]} below.

\begin{align*}
    \E[C(I_p, A)] &= \sum_{}^{} C(I_k, A) \P[I_k] \\
                  &= \frac{1}{|S|} \sum k  \textbf{\quad \quad [*]}\\
                  &= \frac{|S|+1}{2} \\
\end{align*}


Now let $q$ be a probability distribution over the set of deterministic algorithms $\mathcal{A}$ , using Yao's minmax theorem we get:
\begin{align*}
   \frac{|S|+1}{2}  \leq  \max_{I \in S} \E[C(I, A_q)]
\end{align*}

From the last inequality, we can conclude that no randomized algorithm can do better in average that $\frac{|S|+1}{2}$,(there is always an input that has higher cost than that), and hence the the algorithm in \textbf{(b)} is optimal.

\begin{exo}{\ \\}

Let $C = \{x_1, \dots, x_N\}$ be a random cut of the graph, where $\{x_i\}_{1\leq i \leq N}$ representes the edges. We are obviously interested in $\E[N]$, i.e., the expected number of edges in a cut. Let $E = \{e_1, \dots, e_{|E|}\}$ and let the RV $X_i$ be the indicator of edge $e_i$ in $C$.


Clearly $\displaystyle N = \sum_{i=1}^{|E|}X_i$, and hence, $\displaystyle \E[N]= \sum_i^{|E|} \E[X_i]$

Now we prove that $\E (X_i) = 1/2$. Suppose the edge $e_i$ connects the vertices $A$ and $B$. 

\begin{align*}
    \E[X_i] &= \P[X_i=1] \\
            &= \P[\{\text{A random cut contains $e_i$}\}] \\
            &= \P[\{\text{A cut contains one and only one of $A$ or $B$  }\}] \\
\end{align*}

Each cut is defined by a split of vertices $S_1 / S_2$, where $S_1$ selects $j \in \{1, \dots, |V|-1\}$ vertices at random from $V$. Each vertex has 1/2 probability to be in $S_1$ (resp. $S_2$). 
\begin{align*}
    \P[\{ (A,B)\in (S_1, S_2) \lor (A,B)\in (S_2, S_1)\}] &= \P[\{ (A,B)\in (S_1, S_2)\}] + \P[\{(A,B)\in (S_2, S_1)\}] \\
                                                          &= \P[\{ A \in S_1 \land B \in S_2 \}] + \P[\{  A \in S_1 \land B \in S_1\}] \\
                                                          &= \P[\{ A \in S_1\}]\P[\{ B \in S_2 \}] + \P[\{A \in S_1\}] \P[\{B \in S_1\}] \\
                                                          &= 1/2 1/2 + 1/2 1/2 = 1/2
\end{align*}


\end{exo}



\end{document}

