\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[left=1.25in,top=1.25in,right=1.25in,bottom=1.25in,head=1.25in]{geometry}
\usepackage{amsmath,amssymb,amsthm}

\usepackage{import}
\usepackage{xifthen}
\usepackage{pdfpages}
\usepackage{transparent}

\newcommand{\incfig}[1]{%
    \def\svgwidth{\columnwidth}
    \import{./figures/}{#1.pdf_tex}
}



\newtheorem{exo}{Exercise}
\def\P{\mathbb{P}}
\def\E{\mathbb{E}}

\title{Randomised Algorithms \\
Winter term 2022/2023, Exercise Sheet No. 5}

\author{
    \textbf{Authors:} \\
    Ben Ayad, Mohamed Ayoub \\
    Kamzon, Noureddine
}

\begin{document}

\maketitle

%exo1
\begin{exo}{\ \\}
\noindent
\textbf{(a)} We have established  in the notes that the probability of not making any mistakes after $n-t$ contractions is at least $\frac{t(t-1)}{n(n-1)}$, in this case, when $t = n-1$, we would get that this probability is $\frac{n-2}{n} = 1 - \frac{2}{n} $, which is in fact equal to $q_n$. \\

\noindent
\textbf{(b)} We denote the probability that $S_1$ (resp $S_2$) is correct as $P_1$ (resp. $P_2$), we have: 
\begin{align*}
P_1 &= \P[\text{\{Contraction at L4 is correct\}}]\P[\text{\{Output of L5 is correct\}}|\text{\{Contraction at L4 is correct\}}] \\
    &= q_n P(n-1) \\
P_2 &= P(n)
\end{align*}

The algorithm is succesful if either the return at line 7 was a succes (i.e., $S_1$ is a success) or  the return at line 10 was a succes, which yiled the following: 

\begin{align*}
    p(n) &= \P[\text{\{Entered L7\}}]\P[\text{\{Succes\}}|\text{\{entered L7\}}]
    + \P[\text{\{Didn't Enter L7\}}]\P[\text{\{Succes\}}|\text{\{Didnt enter L7\}}] \\
         &= q_n \P[\text{\{Succes\}}|\text{\{entered L7\}}]
    + (1-q_n)\P[\text{\{Succes\}}|\text{\{Didnt enter L7\}}] \\
         &= q_n \P[\text{\{$S_1$ is succesful\}}]
    + (1-q_n)\P[\text{\{The best of $S_1$, $S_2$ was succesful\}}] \\
         &= q_n \P[\text{\{$S_1$ is succesful\}}]
    + (1-q_n)(1 - \P[\text{\{$S_1$ and $S_2$ failed\}}]) \\
         &= q_n P_1 + (1-q_n)[1- (1-P_1)(1-P_2)]  \quad \quad \text{(We will just keep re-arranging after now)} \\
         &= q_n^2 P(n-1) + (1-q_n)[1 - (1-q_nP(n-1))(1-P(n))] \\
         &= q_n^2 P(n-1) + (1-q_n)[P(n) + q_nP(n-1) - q_nP(n-1)P(n)] \\ 
         &= q_nP(n-1) + (1-q_n)P(n) - q_n(1-q_n)P(n-1)P(n) \\ 
    \implies & \\
         q_nP(n)&= q_nP(n-1) - q_n(1-q_n)P(n-1)P(n) \\ 
    \implies & \\
         P(n) &= P(n-1) - (1-q_n)P(n-1)P(n) \quad \quad (\text{We would verify line 1 if $n=2$, hence $q_n$ would never equal $0$ } )
\end{align*}

\noindent
\textbf{(c)} By dividing the equation that we derived in the last question by $P(k)P(k-1)$, we get the following, for $k \in \{3, \dots, n\}$:

\begin{align*}
    \frac{1}{P(k-1)} - \frac{1}{P(k)}  &= - \frac{2}{k}  \\
    \implies & \\
    \sum_{k=3}^{n} \frac{1}{P(k-1)} - \sum_{k=3}^{n} \frac{1}{P(k)}  &=
    - \sum_{k=3}^{n} \frac{2}{k}  \\
    \frac{1}{P(2)} - \frac{1}{P(n)}  &= -\sum_{k=3}^{n} \frac{2}{k}  \\
    \implies &\\
    P(n) = \frac{1}{\sum_{k=3}^{n} \frac{2}{k} + 1} 
\end{align*}

Comparisons of the probability of succes with FastCut:

\begin{itemize} 
    \item GeoContraction has a $\Theta(\frac{1}{\log(n)})$ (Assuming the bounds are exact like suggested in \textbf{(b)} )
    \item FastCut had a $\Omega(\frac{1}{\log(n)})$ 
\end{itemize}


\end{exo}

%exo2
\begin{exo}{\ \\}

Let $X_t$ represent the number of walks that are left to reach home at step $t$. Obviously $X_t \in \{0, \dots, n\}$, and we are interested in computing $\E[T]$ where $T = \inf\{t \geq 0 | X_t = 0 \}$. \\

We have the following:

\begin{align*}
    \E_{(X_t,X_{t+1})}[X_t - X_{t+1}| X_t=s]  
    &= \E_{X_{t+1}}[s- X_{t+1}| X_t=s]  \\
    &= s - \E[X_{t+1}| X_t=s]  \\
\end{align*}

If $s=n$ (we are at the bar), $X_{t+1}$ has two options $\{n, n-1\}$
\begin{align*}
    \E[X_t-X_{t+1} | X_t = s] 
    &= n - n\P[X_{t+1}= n|X_t=s] - (n-1)\P[X_{t+1}=n-1|X_t=s] \\
    &= \frac{1}{5}
\end{align*}


If $0<s<n$, $X_{t+1}$ has two options $\{s-1, s+1\}$
\begin{align*}
    \E[X_t-X_{t+1} | X_t = s] 
    &= s - (s-1)\P[X_{t+1}= s-1|X_t=s] - (s+1)\P[X_{t+1}=s+1|X_t=s] \\
    &= \frac{3}{5} + \frac{2}{5} \\
    &= 1
\end{align*}

Hence, we get, for all $t>0, s \neq 0$:
\[ \frac{1}{5} \leq \E[X_t-X_{t+1} | X_t = s]  \leq 1 \]

Which yields the following bounds, assuming $X_0 = n$:
\[ n \leq \E[T] \leq 5n \]
\end{exo}

%exo3
\begin{exo}{\ \\}
\noindent
\textbf{(a)} As the state $0$ is never reacheable and $X_0 = 1$, $T$ could be formulated as follows: \[T = \inf\{t \geq 1 | X_t = -1 \} \] i.e, the first time we reach the state $s = -1$ (our definition of "succcess", speaking from a geometric distribution terminology). By noting that each $X_t$ is a Bernoulli experiment with $p =1/2$, we conclude that $\E[T] = 1/p = 2$. \\

\noindent
\textbf{(b)} The state we are interested to reach in the definition of $T$ is -1, in the theorem the state of interest is $s = 0$, and $X_t$ only takes positive values in the theorem statement, again, here $X_t$ can take the value $-1$.

We have for $s \neq 0$: $\E[X_{t+1}|X_t = s] = 0$, and hence: 

\[ \E[X_t - X_{t+1} | X_t =s] =  s - \E[X_{t+1}|X_t = s] = s \]

Which yields, $\E[X_t - X_{t+1}| X_t = s] \leq 1$ for all $s \neq 0$. using the additive drift theorem would lead to conclude that $1 \leq E[T]$ \\

\textbf{To make it work}, we define the random process $(Y_t)$ as $Y_t = X_t +1$, clearly $Y_t \in \{0, 1, 2\}$, and 
\begin{align*}
    T 
    &= \inf\{ t \geq 0 | X_t = -1\} \\
    &= \inf\{ t \geq 0 | X_t+ 1 = 0\} \\
    &= \inf\{ t \geq 0 | Y_t = 0\} \\ 
\end{align*}

The way we defined $(Y_t)_{t\geq0}$, and how we formulated $T$ using $(Y_t)$, matches the theorem's assumptions. Moreover we have:
$[s \neq 0 \land \P(Y_t = s)> 0 \implies s=2]$, and hence we only need to verify the theorem's conditions for $s=2$:

\begin{align*}
    \E[Y_t - Y_{t+1}| Y_t  = 2] 
        &= 2 - \E[Y_{t+1}|Y_t = 2] 
        \quad \quad \text{(($Y_{t+1}$ can only move to 0 or 2)}\\
        &= 2 - 2\P[Y_{t+1}=2|Y_t = 2] \\
        &= 2 - 2 \frac{1}{2} \\ 
        &= 1
\end{align*}

And hence, using the additive drift theorem, we get:

\[  \frac{\E[Y_0]}{1} \leq \E[T] \leq \frac{\E[Y_0]}{1} \implies  \E[T] =  2, \text{since $\E[Y_0]=2$} \]

Which is the same as the answer that we got in \textbf{(a)}. 


\end{exo}


%exo4
\begin{exo}{\ \\}
\noindent
\textbf{(a)} Let's first compute $\E[X_t-X_{t+1}| X_t =s]$ for some $0 <s \leq n$:

\begin{align*}
    \E[X_t-X_{t+1}| X_t =s] 
    &= s - \sum_{i = 0}^{s-1} \P[X_{t+1}=i| X_t =s] i \\
    &= s - \frac{1}{s} \sum_{i = 0}^{s-1} i \\
    &= \frac{s+1}{2} 
\end{align*}

Hence, we have $\E[X_t-X_{t+1}| X_t =s] \geq \frac{s+1}{2}$, for all $0 <s \leq n$, with $h(s): s \mapsto \frac{s+1}{2}$ being monotonically increasing, we have verified all assumptions of the Variable Drift Theorem, hence, we can conclude the following:

\begin{align*}
    \E[T]
    &\leq \frac{1}{h(1)} + \int_{{1}}^{{n}} {\frac{1}{h(x)} } \: d{x} \\
    &= 1 + \int_{{1}}^{{n}} {\frac{2}{x+1}} \: d{x} \\
    &= 1 + 2 \int_{{2}}^{{n+1}} {(\ln(x))'} \: d{x} \\
    &= 1 + 2(\ln(n+1)-\ln(2)) \\
    &\leq 2\ln(n+1) \quad \quad \quad ( 1 - 2\ln(2) \approx  -0.39 )
\end{align*}

Using the Additive Drift Theorem (since $\E[X_t-X_{t+1}| X_t =s] \geq 1$, for all $0 <s \leq n$) would lead to conclude that $\E[T] \leq n$, which is less tight than the gap that we obtained using the Variable Drift Theorem. \\

\noindent
\textbf{(b)} The function $h(s)\colon s \mapsto \frac{1}{s}$ isn't monotonically increasing, hence we can't use the Variable Drift Theorem. \\

We have, for $0 <  s \leq n, \quad \E[X_t-X_{t+1}| X_t=s] \geq \frac{1}{n}$, hence, using the Additive Drift Theorem, yields the following: $\E[T] \leq n^2$ \\

\noindent
\textbf{(c)} We have, $h(s): s \mapsto \sqrt{s}$ is monotonically increasing for all $0 < s \leq n$, using the Variable Drift Theorem, we get:

\begin{align*}
    \E[T]
    &\leq \frac{1}{h(1)} + \int_{{1}}^{{n}} {x^{-\frac{1}{2} }} \: d{x} \\
    &\leq 1 + 2 \int_{{1}}^{{n}} {(\sqrt{x})'} \: d{x} \\
    &\leq 2 \sqrt{n} - 1 
\end{align*}

\noindent
\textbf{(d)} Consider the random process $(X_t)_{t \geq 0}$ on state space $\{0, 1, \dots, n\}$, where knowing that $X_t = s$ for $s>0$, $X_{t+1}$ is defined as follows:

\[   
X_{t+1} = 
\begin{cases}
    s-1 &\text{with probability } \frac{1}{s} \\
    s   &\text{with probability } 1 - \frac{1}{s}\\
\end{cases}
\]

For $s>0$ and $t \geq 1$:
\begin{align*}
    \E[X_{t}-X_{t+1}|X_t=s] 
    &= s - \E[X_{t+1}| X_t=s] \\
    &= s - [(s-1)\frac{1}{s} + s(1-\frac{1}{s})] \\
    &= s - [1 - 1/s + s -1] \\
    &= \frac{1}{s} 
\end{align*}


\end{exo}


\end{document}

